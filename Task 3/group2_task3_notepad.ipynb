{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Modeling Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course:** Introduction to Data Science\n",
    "**Lecturer:** Prof. Dr. Hendrik Meth\n",
    "\n",
    "**Group 2:**\n",
    "- Linus Breitenberger\n",
    "- Tristan Ruhm\n",
    "- Prarichut Poachanuan\n",
    "- Anushka Irphale\n",
    "- Patryk Gadziosmki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:30px;background-color:#E31134\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reworking of Train- and Testdata\n",
    "After the feedback we got from Task 2, we did a little bit of reworking to optimize our linear regression Model, before we \n",
    "tackle Task 3.\n",
    "\n",
    "Some of our Optimization includes:\n",
    "\n",
    "    -Removed temp and kept atemp during feature selection, as using both would create issues with multicorrelation.\n",
    "    -remove the 'casual' and 'registered' labels, because we only use 'cnt'\n",
    "    -checked out how 'mnth' is distributed ? (Anectode from the lecture)\n",
    "    -kept 'instant', because its relevant apparently\n",
    "    \n",
    "Since we changed our dataset, we also tested our Models again to compare if the Model improved.\n",
    "\n",
    "<div style=\"width:100%;height:30px;background-color:#E31134\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:30px;background-color:#E31134\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Summary of Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reworking and Optimization of train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our final model for Task 2 didn't seem to be optimal and some details had been overseen, we decided to do a rework of our train and test datas and optimize it.\n",
    "\n",
    "Because of the high correlation with 'cnt', we decided to keep 'instant' in the data set. The features 'temp' and 'atemp' had a multicorrelation, so we kept 'atemp', which had a minimal better correlation, in and dropped 'temp'. We also removed the 'casual' and 'registered' labels, since we only use 'cnt'.\n",
    "\n",
    "In the end we tested our models with the new test data and had following result:\n",
    "- `MAE`: 923.977 \n",
    "- `R^2 value of the model`:  0.36870153666640637\n",
    "\n",
    "The Mean Absolute Error (MAE) has an improvement. On the opposite, the Coefficient of Determination (R^2) has a deterioration. We exported the reworked train- and testdata to csv and used for the `base linear regression` and the `model optimization`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first step, we refined the feature and label for our model buidling with splitting the training data into `train_features` and `train_labels` and the testdata into `test_features` and `test_label`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our initial model building, we employed linear regression to predict the bike rental count ('cnt') using labeled training data.\n",
    "\n",
    "### Model Selection and Training:\n",
    "We instantiated a linear regression model using the `linear_model.LinearRegression()` function. The model was trained on the training features (`train_features`) and labels (`train_labels`) using the `fit` method.\n",
    "\n",
    "### Model Coefficients:\n",
    "- The coefficients of the linear regression model, representing the weights assigned to each feature, are printed using `print(baseline_model.coef_)`. These coefficients provide insights into the contribution of each feature to the prediction of the target variable\n",
    "\n",
    "Like in the last task, this linear regression model serves as our baseline model, providing a starting point for evaluation and potential refinement in subsequent stages of model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better model optimization, we created further model versions besides of the linear regression. Beside of linear regression, scikit-learn has various other algorithms. With testing these algortihms, we can figure out, which model has the best result. In the following, we present the results of each algorithm.\n",
    "\n",
    "For each model, we used the method `forward selection`, to get the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the polynomial regression, we used the function `makepipeline(PolynomialFeatures())`. It gives out multiple results, which  will run through `linear_model.LinearRegression()`, to get one value as a prediction.\n",
    "\n",
    "- degree=2 -> fault value = best value, because 1 is linear, 3 has too much exponantial growth\n",
    "- interaction_only='false'\n",
    "- include_bias=True -> extra col with bias over zero\n",
    "- order= C  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 K-Nearest-neighbours Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the K-nearest-neighbours regression, we compared each value of 'cnt' with his 10 nearest neighbour-values. For that, we used the function `KNeighborsRegressor()` to predict a numeric label, which is the average of all 10 values. A special aspect is that no linear relationships are required to build a model.\n",
    "\n",
    "- n_neighbour = 3; 3 had better output.\n",
    "- weights= uniform ; all neighbour are same wieghted, no priorities\n",
    "- algorithm=auto ; automatic selecting of the most appropriate algrotihm\n",
    "- leaf_size= default\n",
    "- p = 10; best value\n",
    "- metric = default \n",
    "- metric_params = None\n",
    "- n_jobs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Regression Tree / Decision Tree Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regression tree makes it possible to handle nominal features and non-linear relationships. We used the `DecisionTreeRegressor()`-function.\n",
    "\n",
    "- criterion = absolute_error\n",
    "- splitter = best; choosing which path \n",
    "- max_depth = 5; depth of tree, better value\n",
    "- min_sample_split = default\n",
    "- min_sample_leaf = 5 ;minimal number of sample in leaf, better value\n",
    "- min_wieght_fraction_leaf = 0.0 \n",
    "- max_features = None; explicit None, all features should taken in a split\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Support Vector Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Support Vector Regression defines a hyperplane, which can be linear, polynomial or gaussian.\n",
    "\n",
    "First, we used the function `SVR()` with a polynomial kernel, since the evaluation of polynomial regression had a good result. The result of it was not so good, so we concluded to take the linear kernel, which had a better result.\n",
    "- kernel = linear; \n",
    "- c =100 ; regularization_parameter \n",
    "- epsilon ; \n",
    "- max_iter = -1; no limit for iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Furhter Models\n",
    "\n",
    "| Iteration | Selected Features             | Performance (RÂ²) | Decision          |\n",
    "|------------|-------------------------------|------------------|-------------------|\n",
    "| 1          | season                        | 0.114            | -                 |\n",
    "| 2          | season, yr                    | 0.298            | keep yr           |\n",
    "| 3          | season, yr, mnth              | 0.298            | not keep mnth     |\n",
    "| 4          | season, yr, holiday           | 0.298            | not keep holiday  |\n",
    "| 5          | season, yr, weekday           | 0.289            | not keep weekday  |\n",
    "| 6          | season, yr, workingday        | 0.296            | not keep workingday|\n",
    "| 7          | season, yr, weathersit        | 0.332            | keep weathersit   |\n",
    "| 8          | season, yr, weathersit, temp  | 0.379            | keep temp         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better comparison, we took "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Interpretation & Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
